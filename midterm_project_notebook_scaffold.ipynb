{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# ðŸ§ª Midterm Project: Data Science with Python â€” Notebook Scaffold\n",
        "\n",
        "**Generated:** 2025-10-15 16:01\n",
        "\n",
        "This notebook is a scaffold aligned to your assignment requirements:\n",
        "- Data acquisition, cleaning, preprocessing\n",
        "- EDA & visualizations (â‰¥ 3 plots)\n",
        "- Two ML models + â‰¥ 2 evaluation metrics\n",
        "- Reproducible and well-commented\n",
        "\n",
        "> Replace any **TODO** blocks with your team's specifics (dataset path, target column, decisions, etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 0. Project Config (EDIT ME)\n",
        "\n",
        "Fill these in for your chosen dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Project Configuration ===\n",
        "CONFIG = {\n",
        "    # TODO: set the absolute/relative path to your dataset file (CSV recommended for reproducibility)\n",
        "    \"data_path\": \"PATH/TO/YOUR_DATA.csv\",\n",
        "\n",
        "    # TODO: set your target column name after you inspect the dataset\n",
        "    \"target\": None,  # e.g., \"SalePrice\" or \"churned\"\n",
        "\n",
        "    # Optional: rows to sample for quick iteration (set to None to use full data)\n",
        "    \"row_limit\": None,\n",
        "\n",
        "    # Optional: treat specific values as NaN\n",
        "    \"na_values\": [\"NA\", \"N/A\", \"\", \"?\", \"null\", \"None\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 1. Data Acquisition\n",
        "\n",
        "- **Source**: Describe where you obtained the data (Kaggle/UCI/API/etc.).\n",
        "- **License**: Note any usage restrictions if applicable.\n",
        "- **Method**: If from an API, paste example request; if file, document download steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Load Data ===\n",
        "assert CONFIG[\"data_path\"] != \"PATH/TO/YOUR_DATA.csv\", \"Please set CONFIG['data_path'] to your dataset file.\"\n",
        "\n",
        "read_kwargs = {}\n",
        "if CONFIG[\"na_values\"]:\n",
        "    read_kwargs[\"na_values\"] = CONFIG[\"na_values\"]\n",
        "\n",
        "df = pd.read_csv(CONFIG[\"data_path\"], **read_kwargs)\n",
        "\n",
        "if CONFIG[\"row_limit\"]:\n",
        "    df = df.sample(CONFIG[\"row_limit\"], random_state=RANDOM_STATE)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 2. Cleaning\n",
        "\n",
        "Document decisions:\n",
        "- How many duplicates? Dropped?\n",
        "- Which columns had missing values? Strategy per column (drop vs. impute) and **why**.\n",
        "- Any obvious invalid categories/out-of-range numeric values corrected?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Inspect Raw ===\n",
        "display(df.info())\n",
        "display(df.describe(include='all').T)\n",
        "\n",
        "# === Basic Cleaning Example (customize for your data) ===\n",
        "\n",
        "# 1) Remove duplicate rows if any\n",
        "before = len(df)\n",
        "df = df.drop_duplicates()\n",
        "after = len(df)\n",
        "print(f\"Removed {before - after} duplicate rows.\")\n",
        "\n",
        "# 2) Strip whitespace from object (string) columns\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    df[col] = df[col].astype(str).str.strip()\n",
        "\n",
        "# 3) Optional: drop columns with excessive missingness (> 60%) â€” justify in report\n",
        "missing_ratio = df.isna().mean().sort_values(ascending=False)\n",
        "print(\"Missing ratio (top 10):\")\n",
        "display(missing_ratio.head(10))\n",
        "\n",
        "# Example threshold (EDIT/justify)\n",
        "THRESH = 0.60\n",
        "to_drop = missing_ratio[missing_ratio > THRESH].index.tolist()\n",
        "if to_drop:\n",
        "    print(\"Dropping columns due to high missingness:\", to_drop)\n",
        "    df = df.drop(columns=to_drop)\n",
        "\n",
        "print(\"Shape after cleaning:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Preprocessing\n",
        "\n",
        "Use at least **two** techniques (e.g., encoding categoricals + scaling numerics).  \n",
        "Engineered features are a plus; explain the rationale.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Identify Features & Target ===\n",
        "assert CONFIG[\"target\"] is not None, \"Set CONFIG['target'] to your target column name.\"\n",
        "assert CONFIG[\"target\"] in df.columns, f\"Target '{CONFIG['target']}' not found in columns.\"\n",
        "\n",
        "y = df[CONFIG[\"target\"]]\n",
        "X = df.drop(columns=[CONFIG[\"target\"]])\n",
        "\n",
        "# Drop columns that are entirely NA after cleaning (defensive)\n",
        "X = X.dropna(axis=1, how='all')\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y if y.nunique() < 20 else None\n",
        ")\n",
        "\n",
        "# Column types\n",
        "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(\"Categorical features:\", cat_cols[:10], \"...\" if len(cat_cols) > 10 else \"\")\n",
        "print(\"Numeric features:\", num_cols[:10], \"...\" if len(num_cols) > 10 else \"\")\n",
        "\n",
        "# Preprocessing pipelines\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\",  __import__(\"sklearn\").impute.SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\",   StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\",  __import__(\"sklearn\").impute.SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\",  OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_cols),\n",
        "        (\"cat\", categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Heuristic: decide if task is classification or regression based on target dtype/cardinality\n",
        "is_classification = (y.dtype.kind in \"biu\" and y.nunique() < max(50, int(0.2 * len(y)))) or y.dtype == \"object\"\n",
        "print(\"Task type:\", \"Classification\" if is_classification else \"Regression\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 4. Exploratory Data Analysis (EDA) + Visualizations\n",
        "\n",
        "Create at least **three** distinct plots. Suggestions:\n",
        "- Histograms of key numeric features\n",
        "- Box plots to inspect outliers\n",
        "- Scatter plots showing relationships with the target (if numeric)\n",
        "- Correlation heatmap (for numeric features)\n",
        "\n",
        "> Ensure titles, axis labels, and clear legends where applicable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Basic EDA ===\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "display(X_train.describe(include='all').T)\n",
        "\n",
        "# 1) Histogram: numeric columns\n",
        "for col in X_train.select_dtypes(include=[np.number]).columns[:3]:\n",
        "    plt.figure()\n",
        "    X_train[col].hist(bins=30)\n",
        "    plt.title(f\"Histogram of {col}\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()\n",
        "\n",
        "# 2) Box plot: first numeric column (if available)\n",
        "num_cols_plot = X_train.select_dtypes(include=[np.number]).columns\n",
        "if len(num_cols_plot) > 0:\n",
        "    c = num_cols_plot[0]\n",
        "    plt.figure()\n",
        "    plt.boxplot(X_train[c].dropna(), vert=True)\n",
        "    plt.title(f\"Box Plot of {c}\")\n",
        "    plt.ylabel(c)\n",
        "    plt.show()\n",
        "\n",
        "# 3) Correlation heatmap (numeric only)\n",
        "if len(num_cols_plot) > 1:\n",
        "    corr = X_train[num_cols_plot].corr()\n",
        "    plt.figure()\n",
        "    plt.imshow(corr, aspect='auto', interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.title(\"Correlation Heatmap (numeric features)\")\n",
        "    plt.xticks(range(len(num_cols_plot)), num_cols_plot, rotation=90)\n",
        "    plt.yticks(range(len(num_cols_plot)), num_cols_plot)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 5. Modeling\n",
        "\n",
        "Train **two** algorithms appropriate to your task.  \n",
        "Weâ€™ll build a baseline linear model and a Random Forest with light tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Build Models ===\n",
        "\n",
        "results = []\n",
        "\n",
        "if is_classification:\n",
        "    # Model A: Logistic Regression (baseline)\n",
        "    clf_lr = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
        "    ])\n",
        "    clf_lr.fit(X_train, y_train)\n",
        "    y_pred_lr = clf_lr.predict(X_test)\n",
        "    y_proba_lr = None\n",
        "    try:\n",
        "        y_proba_lr = clf_lr.predict_proba(X_test)[:, 1]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred_lr)\n",
        "    prec = precision_score(y_test, y_pred_lr, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred_lr, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred_lr, average='weighted', zero_division=0)\n",
        "    roc = roc_auc_score(y_test, y_proba_lr, multi_class='ovr') if (y_proba_lr is not None and y.nunique()>2) else (roc_auc_score(y_test, y_proba_lr) if y_proba_lr is not None and y.nunique()==2 else None)\n",
        "\n",
        "    results.append({\n",
        "        \"model\": \"LogisticRegression\",\n",
        "        \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": roc\n",
        "    })\n",
        "\n",
        "    # Model B: RandomForestClassifier with light tuning\n",
        "    clf_rf = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", RandomForestClassifier(random_state=RANDOM_STATE))\n",
        "    ])\n",
        "\n",
        "    param_grid = {\n",
        "        \"model__n_estimators\": [200, 400],\n",
        "        \"model__max_depth\": [None, 10, 20],\n",
        "        \"model__min_samples_split\": [2, 5]\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(clf_rf, param_grid, cv=3, n_jobs=-1, scoring=\"f1_weighted\")\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    best_rf = grid.best_estimator_\n",
        "    y_pred_rf = best_rf.predict(X_test)\n",
        "    try:\n",
        "        y_proba_rf = best_rf.predict_proba(X_test)[:, 1] if y.nunique()==2 else None\n",
        "    except Exception:\n",
        "        y_proba_rf = None\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred_rf)\n",
        "    prec = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
        "    roc = roc_auc_score(y_test, y_proba_rf) if y_proba_rf is not None else None\n",
        "\n",
        "    results.append({\n",
        "        \"model\": \"RandomForestClassifier (tuned)\",\n",
        "        \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": roc,\n",
        "        \"best_params\": grid.best_params_\n",
        "    })\n",
        "\n",
        "else:\n",
        "    # Regression path\n",
        "    # Model A: Linear Regression (baseline)\n",
        "    reg_lr = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", LinearRegression())\n",
        "    ])\n",
        "    reg_lr.fit(X_train, y_train)\n",
        "    y_pred_lr = reg_lr.predict(X_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
        "    mae = mean_absolute_error(y_test, y_pred_lr)\n",
        "    r2 = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "    results.append({\n",
        "        \"model\": \"LinearRegression\",\n",
        "        \"rmse\": rmse, \"mae\": mae, \"r2\": r2\n",
        "    })\n",
        "\n",
        "    # Model B: RandomForestRegressor with light tuning\n",
        "    reg_rf = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", RandomForestRegressor(random_state=RANDOM_STATE))\n",
        "    ])\n",
        "\n",
        "    param_grid = {\n",
        "        \"model__n_estimators\": [200, 400],\n",
        "        \"model__max_depth\": [None, 10, 20],\n",
        "        \"model__min_samples_split\": [2, 5]\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(reg_rf, param_grid, cv=3, n_jobs=-1, scoring=\"neg_root_mean_squared_error\")\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    best_rf = grid.best_estimator_\n",
        "    y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
        "    mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "    r2 = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "    results.append({\n",
        "        \"model\": \"RandomForestRegressor (tuned)\",\n",
        "        \"rmse\": rmse, \"mae\": mae, \"r2\": r2,\n",
        "        \"best_params\": grid.best_params_\n",
        "    })\n",
        "\n",
        "# Display results\n",
        "pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 6. Interpretation (Plain English)\n",
        "\n",
        "Summarize what the metrics mean in context of your problem:\n",
        "- If classification: Which model generalizes better? Discuss precision/recall tradeoffs.\n",
        "- If regression: Compare RMSE/MAE/RÂ² and what they imply for prediction quality.\n",
        "- Note any limitations, class imbalance, or data constraints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 7. Save Artifacts (Optional)\n",
        "\n",
        "Export cleaned data, model, or figures for your report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Save Outputs ===\n",
        "OUTPUT_DIR = \"outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Example: save cleaned dataset\n",
        "df.to_csv(os.path.join(OUTPUT_DIR, \"cleaned_dataset.csv\"), index=False)\n",
        "\n",
        "# Save results table\n",
        "_ = pd.DataFrame(results)\n",
        "_.to_csv(os.path.join(OUTPUT_DIR, \"model_results.csv\"), index=False)\n",
        "\n",
        "print(\"Saved:\", os.listdir(OUTPUT_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Setup & Imports ===\n",
        "# If you don't have some packages, install them first (uncomment the next lines in your own environment).\n",
        "# !pip install pandas numpy scikit-learn matplotlib\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    mean_squared_error, mean_absolute_error, r2_score\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "# Plot settings (do not set specific colors per project rules)\n",
        "plt.rcParams.update({'figure.figsize': (8, 5)})\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
